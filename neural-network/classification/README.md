# Classificação de picos de consumo

Esse algoritmo tem como objetivo prever picos de consumo de CPU baseado na relação entre as varíaveis das 60 primeiras ocorrências (1 hora) com os picos das próximas 30 ocorrências.

### O ciclo de treino:

<img src="https://github.com/vinhali/advanced_monitoring/blob/master/neural-network/classification/img/estrutura.png?raw=true" width="500px" height="600px">

### Normalização:

No caso de redes neurais é importante que as características
estejam em um range numérico padronizado, por exemplo, entre 0 a 1. Isto possibilita que o algoritmo convirja mais rápido ao resultado.

                 m1,d1           m2,d2           m3,d3           m4,d4           m5,d5   0-20  20-40  40-60  60-80  80-100
    0   [0.573, 0.699]  [0.412, 0.224]  [0.696, 0.512]  [0.326, 0.314]   [0.79, 0.685]  1.000    0.5      0      0       0
    1   [0.456, 0.251]  [0.629, 0.523]  [0.344, 0.286]    [0.8, 0.699]    [0.721, 1.0]  1.000    0.5      0      0       0
    2   [0.658, 0.531]  [0.339, 0.282]  [0.592, 0.614]    [0.859, 1.0]  [0.365, 0.283]  1.000    0.5      0      0       0
    3   [0.396, 0.314]   [0.29, 0.201]      [1.0, 1.0]   [0.34, 0.288]  [0.886, 0.647]  1.000    0.5      0      0       0
    4   [0.379, 0.315]      [1.0, 1.0]  [0.302, 0.248]  [0.929, 0.655]  [0.328, 0.308]  1.000    0.5      0      0       0
    5       [1.0, 1.0]  [0.274, 0.249]  [0.679, 0.536]   [0.52, 0.413]  [0.382, 0.337]  1.000    0.5      0      0       0

    Até a linha 47 ...
    
## Explicação da normalização:
 
### Entrada da camada:

> *m1 = Média de 12 leituras (Em uma janela de 60 dados) - Exemplo ((2 + 5 + 7 ...) / 12*

> *d1 = desvio padrão dos 12 dados*

E assim sucessivamente até formar *m5, d5 (12x5 = 60)*

<img src="https://github.com/vinhali/advanced_monitoring/blob/master/neural-network/classification/img/input_layer.png?raw=true" width="600px" height="300px"/>

### Saída da camada:

> *0-20 = Quantas vezes os valores são repetidos no intervalo de 0 a 20 nas próximas 30 leituras (Linha 61,62,62 ...)*

E assim sucessivamente até formar *20-40.40-60.60-80.80-100*

<img src="https://github.com/vinhali/advanced_monitoring/blob/master/neural-network/classification/img/output_layer.png?raw=true" width="600px" height="300px"/>

### Formúla para cada item:

*Média (m1,m2,m3,m4,m5):*

<img src="https://github.com/vinhali/advanced_monitoring/blob/master/neural-network/classification/img/mat5.png?raw=true" width="150px" height="75px"/>

*Desvio padrão (d1,d2,d3,d4,d5):*

<img src="https://github.com/vinhali/advanced_monitoring/blob/master/neural-network/classification/img/mat4.png?raw=true" width="150px" height="100px"/>

### Transformando em 0 e 1

Em seguida é selecionado a maior ocorrência de cada coluna e dividido todos os valores da respectiva coluna pela maior ocorrência, exemplo:

> m1 = (Xn > Xn) / Xn

### Rectified Linear Unit:

O modelo sequencial permite inserir camadas em série, onde o output da primeira camada serve como input da segunda, e assim por diante. Usaremos a função “relu”, Rectified Linear Unit, que é dada pela formula:

<img src="https://github.com/vinhali/advanced_monitoring/blob/master/neural-network/classification/img/mat2.png?raw=true"/>

Graficamente:

<img src="https://github.com/vinhali/advanced_monitoring/blob/master/neural-network/classification/img/mat3.jpeg?raw=true"/>

### Sumário (Estrutura da rede):

    Layer (type)                 Output Shape              Param #   
    =================================================================
    layer1 (Dense)               (None, 2)                 22        
    _________________________________________________________________
    layer2 (Dense)               (None, 3)                 9         
    _________________________________________________________________
    layer3 (Dense)               (None, 10)                40        
    =================================================================
    Total params: 71
    Trainable params: 71
    Non-trainable params: 0
    
### Treino (Precisão histórica do algoritmo):

    Epoch 1/2
    6/6 [==============================] - 0s 4ms/step - loss: 0.1451 - mae: 0.3251
    Epoch 2/2
    6/6 [==============================] - 0s 3ms/step - loss: 0.1411 - mae: 0.3195

### Resultado (Previsão):

    array([[ 0.20917255,  0.07620977,  0.07446235,  0.15165696,  0.16146947,
             0.04009043,  0.08959188,  0.1895957 ,  0.00107612, -0.00426   ],
           [ 0.30251867,  0.05599844,  0.05198246,  0.1986706 ,  0.21479487,
            -0.01329821,  0.07939973,  0.26792583, -0.08923449, -0.09692957],
           [ 0.11986876,  0.09554585,  0.09596875,  0.10667922,  0.11045333,
             0.09116708,  0.09934264,  0.11465764,  0.08747587,  0.08439653],
           [ 0.2319001 ,  0.07128879,  0.06898903,  0.16310365,  0.17445293,
             0.02709156,  0.08711033,  0.20866722, -0.02091237, -0.02682284],
           [ 0.3531626 ,  0.045033  ,  0.03978624,  0.22417733,  0.24372597,
            -0.04226364,  0.0738701 ,  0.310423  , -0.13823155, -0.14720643],
           [ 0.17480445,  0.08365116,  0.08273898,  0.1343475 ,  0.14183617,
             0.05974701,  0.09334441,  0.16075617,  0.03432662,  0.029859  ],
           [ 0.1943776 ,  0.07941318,  0.07802531,  0.1442055 ,  0.15301764,
             0.04855229,  0.09120728,  0.17718072,  0.01538996,  0.01042771],
           [ 0.20899788,  0.07624759,  0.07450441,  0.15156898,  0.1613697 ,
             0.04019032,  0.08961094,  0.18944913,  0.0012451 , -0.00408661],
           [ 0.18787116,  0.08082195,  0.07959221,  0.14092854,  0.14930074,
             0.0522736 ,  0.09191769,  0.17172094,  0.02168481,  0.01688699],
           [ 0.15979426,  0.08690117,  0.08635378,  0.12678763,  0.13326138,
             0.06833199,  0.09498332,  0.14816058,  0.0488487 ,  0.0447604 ],
           [ 0.11324486,  0.09698006,  0.09756394,  0.10334311,  0.10666933,
             0.09495557,  0.10006588,  0.10909929,  0.09388436,  0.09097241],
           [ 0.13361531,  0.09256944,  0.09265827,  0.11360265,  0.11830626,
             0.08330484,  0.0978417 ,  0.12619288,  0.07417633,  0.0707496 ],
           [ 0.1732268 ,  0.08399275,  0.08311891,  0.13355292,  0.14093493,
             0.06064933,  0.09351666,  0.15943232,  0.03585295,  0.0314252 ],
           [ 0.16486791,  0.08580261,  0.08513193,  0.12934297,  0.13615978,
             0.06543014,  0.09442934,  0.15241808,  0.04394003,  0.03972352],
           [ 0.16436985,  0.08591045,  0.08525187,  0.12909214,  0.13587525,
             0.065715  ,  0.09448372,  0.15200013,  0.04442188,  0.04021796],
           [ 0.17930907,  0.08267581,  0.08165416,  0.13661624,  0.14440951,
             0.05717063,  0.09285256,  0.16453618,  0.02996848,  0.02538703],
           [ 0.11056045,  0.09756128,  0.09821041,  0.1019911 ,  0.10513581,
             0.0964909 ,  0.10035899,  0.1068467 ,  0.09648148,  0.09363737],
           [ 0.15106842,  0.08879049,  0.08845516,  0.12239289,  0.1282766 ,
             0.07332266,  0.09593606,  0.14083841,  0.05729078,  0.05342299],
           [ 0.20139797,  0.07789312,  0.07633465,  0.14774129,  0.15702814,
             0.04453704,  0.09044075,  0.18307178,  0.00859788,  0.00345822],
           [ 0.12466141,  0.09450814,  0.09481458,  0.10909303,  0.1131912 ,
             0.08842596,  0.09881935,  0.11867933,  0.08283906,  0.07963861],
           [ 0.13607922,  0.09203596,  0.0920649 ,  0.11484359,  0.1197138 ,
             0.08189563,  0.09757268,  0.12826043,  0.07179255,  0.06830356],
           [ 0.15403172,  0.08814887,  0.08774152,  0.12388535,  0.12996945,
             0.07162783,  0.09561251,  0.14332503,  0.05442384,  0.05048116],
           [ 0.11799258,  0.09595208,  0.09642058,  0.10573429,  0.10938153,
             0.09224015,  0.0995475 ,  0.11308327,  0.08929103,  0.0862591 ],
           [ 0.12754256,  0.09388431,  0.09412073,  0.11054412,  0.1148371 ,
             0.0867781 ,  0.09850477,  0.12109701,  0.0800516 ,  0.07677834],
           [ 0.18068707,  0.08237745,  0.0813223 ,  0.13731028,  0.14519672,
             0.05638248,  0.09270211,  0.16569251,  0.02863529,  0.02401901],
           [ 0.15039444,  0.08893642,  0.08861747,  0.12205344,  0.12789159,
             0.07370814,  0.09600965,  0.14027286,  0.05794284,  0.05409209],
           [ 0.15945196,  0.08697528,  0.08643621,  0.12661524,  0.13306583,
             0.06852776,  0.09502069,  0.14787334,  0.04917986,  0.04510022],
           [ 0.16667455,  0.08541144,  0.08469684,  0.1302529 ,  0.13719186,
             0.06439684,  0.09423208,  0.15393409,  0.04219212,  0.03792996],
           [ 0.11056045,  0.09756128,  0.09821041,  0.1019911 ,  0.10513581,
             0.0964909 ,  0.10035899,  0.1068467 ,  0.09648148,  0.09363737],
           [ 0.13172661,  0.09297838,  0.09311311,  0.11265141,  0.1172273 ,
             0.08438507,  0.09804793,  0.12460799,  0.07600362,  0.07262462],
           [ 0.18500437,  0.08144267,  0.0802826 ,  0.13948467,  0.14766304,
             0.05391324,  0.09223071,  0.16931531,  0.02445838,  0.019733  ],
           [ 0.14197609,  0.09075916,  0.0906448 ,  0.11781355,  0.12308248,
             0.07852295,  0.09692882,  0.1332087 ,  0.06608743,  0.06244942],
           [ 0.12970962,  0.0934151 ,  0.09359885,  0.11163556,  0.11607507,
             0.08553867,  0.09826815,  0.12291546,  0.07795502,  0.07462698],
           [ 0.15665524,  0.08758083,  0.08710972,  0.12520668,  0.13146816,
             0.07012732,  0.09532605,  0.14552651,  0.05188563,  0.04787667],
           [ 0.18355748,  0.08175595,  0.08063105,  0.13875595,  0.14683647,
             0.05474078,  0.09238869,  0.16810116,  0.02585822,  0.02116942],
           [ 0.14909114,  0.08921861,  0.08893133,  0.12139703,  0.12714706,
             0.07445355,  0.09615195,  0.13917921,  0.05920375,  0.05538593],
           [ 0.17190252,  0.08427949,  0.08343783,  0.13288595,  0.14017841,
             0.06140675,  0.09366126,  0.15832107,  0.03713417,  0.03273989],
           [ 0.16558981,  0.08564632,  0.08495808,  0.12970656,  0.13657217,
             0.06501726,  0.09435052,  0.15302384,  0.04324161,  0.03900685],
           [ 0.1831524 ,  0.08184365,  0.0807286 ,  0.13855195,  0.14660507,
             0.05497245,  0.09243292,  0.16776127,  0.02625012,  0.02157154],
           [ 0.16804296,  0.08511516,  0.08436731,  0.13094209,  0.13797358,
             0.0636142 ,  0.09408267,  0.15508236,  0.04086823,  0.03657148],
           [ 0.11056045,  0.09756128,  0.09821041,  0.1019911 ,  0.10513581,
             0.0964909 ,  0.10035899,  0.1068467 ,  0.09648148,  0.09363737],
           [ 0.13319206,  0.09266108,  0.0927602 ,  0.11338948,  0.11806447,
             0.08354691,  0.09788792,  0.12583771,  0.07458581,  0.07116978],
           [ 0.2246547 ,  0.07285757,  0.07073389,  0.15945452,  0.1703139 ,
             0.03123552,  0.08790143,  0.20258735, -0.01390258, -0.01962996],
           [ 0.11056045,  0.09756128,  0.09821041,  0.1019911 ,  0.10513581,
             0.0964909 ,  0.10035899,  0.1068467 ,  0.09648148,  0.09363737],
           [ 0.14918038,  0.08919929,  0.08890984,  0.12144198,  0.12719804,
             0.07440251,  0.09614221,  0.1392541 ,  0.05911742,  0.05529735],
           [ 0.19287933,  0.07973757,  0.07838613,  0.1434509 ,  0.15216173,
             0.04940921,  0.09137087,  0.17592347,  0.0168395 ,  0.01191511],
           [ 0.22344843,  0.07311875,  0.07102439,  0.15884697,  0.16962479,
             0.03192544,  0.08803314,  0.20157512, -0.01273552, -0.01843242]],
          dtype=float32)
